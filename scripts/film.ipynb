{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping des données et création d'un csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des fonctions qui permettent de scrapper les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import re    \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_films(nb_page = 3) : \n",
    "    \"\"\"permet de récupérer les liens de chaque film de la page du site web inital\"\"\"\n",
    "\n",
    "    # pour stocker les url des pages web des films \n",
    "    url_enfants = []\n",
    "\n",
    "    for page in range(1,nb_page ):  # nombre de page \n",
    "        url_page = f\"https://www.allocine.fr/films/?page={page}\"\n",
    "        soup = BeautifulSoup(requests.get(url_page).text, 'html.parser')\n",
    "\n",
    "        for lien_film in soup.find_all(class_ = \"meta-title-link\") : # avoir les liens\n",
    "            if \"href\" in str(lien_film) : \n",
    "                regex_url = re.search(r'href=\"(.*)\"', str(lien_film)).groups()[0]\n",
    "                url_enfants.append('http://allocine.fr'+regex_url)\n",
    "\n",
    "    return set(url_enfants) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_note_et_nb_avis(lien_avis) : \n",
    "\n",
    "    \"\"\" prends un lien et retourne un tuple stockant le nb d'avis et de la note moyenne pour chaque film\"\"\"\n",
    "\n",
    "    soup_avis = BeautifulSoup(requests.get(str(lien_avis)).content, 'html.parser')   \n",
    "\n",
    "    # avoir la note et nb_avis \n",
    "    for note_nombre in soup_avis.find_all(class_  = \"gd gd-gap-15 gd-xs-1 reviews-note-holder\") : \n",
    "        try : \n",
    "            regex_note = re.findall(r'\"note\">([0-9,]+)<', str(note_nombre))[0].replace(',', '.')\n",
    "            regex_nb_avis = re.findall(r'([0-9]+) critiques spectateurs', str(note_nombre))[0]\n",
    "\n",
    "            if isinstance(float(regex_note), float) and isinstance(float(regex_nb_avis), float) :      \n",
    "                return regex_note, regex_nb_avis\n",
    "\n",
    "        except IndexError: \n",
    "            return 'vide' , 'vide'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commentaire(lien_avis) : \n",
    "\n",
    "    \n",
    "    try :\n",
    "        commentaire =[] # afin de stocker tous les commentaire  \n",
    "        soup_commentaire = BeautifulSoup(requests.get(str(lien_avis)).content, 'html.parser')   \n",
    "        \n",
    "        for com in soup_commentaire.find_all(class_ = \"content-txt review-card-content\") : \n",
    "            commentaire.append( com.text) \n",
    "        \n",
    "        return commentaire\n",
    "\n",
    "    except TypeError: \n",
    "        return \"vide\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_info_de_base(soup_film_base) : \n",
    "\n",
    "    try : \n",
    "        for info_film in soup_film_base.find_all(class_ = 'meta-body-item meta-body-info') :\n",
    "\n",
    "            # recupération des dates \n",
    "            regex_date =  re.findall(r\"[0-9]+ [a-zA-Zéèû]+ [0-9]+\", str(info_film))[0]\n",
    "\n",
    "            # récupération de la durée \n",
    "            regex_duree = re.findall(r\"[0-9]{1,3}h [0-9]+min\", str(info_film))[0]\n",
    "\n",
    "            # récupération dy type de films \n",
    "            regex_type =  re.findall(r\">([a-zA-Z éè]+)<\", str(info_film))\n",
    "\n",
    "    except IndexError:  # eviter erreur  manque de data sur le site web\n",
    "        regex_date = 'vide'\n",
    "        regex_duree = 'vide'\n",
    "        regex_type = 'vide'\n",
    "    \n",
    "    return regex_date, regex_duree, regex_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ajout_nombre_avis_et_note(soup_film_base ) : \n",
    "    \"\"\" retourne le lien de page de chaque films ou se trouve les avis et appel chaque lien sur la fonction get_note_et_nb_avis\"\"\"\n",
    "    \n",
    "    # récupération des liens des avis dans la liste liens_avis\n",
    "    for page_avis in soup_film_base.find_all(class_=\"end-section-link\") : \n",
    "\n",
    "        # récupération du lien avis         \n",
    "        regex_lien_avis =  re.findall(r'href=\"(/.*/critiques/spectateurs/)', str(page_avis)) \n",
    "        if len(regex_lien_avis) > 0 :    \n",
    "            lien_avis = \"http://allocine.fr\" + regex_lien_avis[0]  \n",
    "\n",
    "            return get_note_et_nb_avis(lien_avis), get_commentaire(lien_avis) \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_donnees_film() : \n",
    "\n",
    "    \"\"\"retourne un dictionnaire qui permet d'avoir toutes les info sur les films\"\"\"\n",
    "\n",
    "    url_films = get_url_films()\n",
    "    donnees_film = {} # stocker les données\n",
    "\n",
    "    # recup html de chaque page film \n",
    "    for film in url_films : \n",
    "        soup_film = BeautifulSoup(requests.get(str(film)).text, 'html.parser') \n",
    "\n",
    "        # recupération des titres \n",
    "        for titre_html in soup_film.find_all(class_ = 'titlebar-title titlebar-title-lg') : \n",
    "            donnees_film[titre_html.text] = []\n",
    "\n",
    "        # recupération des info\n",
    "        donnees_film[titre_html.text].append(get_info_de_base(soup_film))\n",
    "            \n",
    "        #récupération du nb_avis et note \n",
    "        try : \n",
    "            donnees_film[titre_html.text].append( ajout_nombre_avis_et_note(soup_film )[0] ) \n",
    "        except TypeError:\n",
    "            donnees_film[titre_html.text].append(('vide','vide'))\n",
    "\n",
    "        # récupération commentaire \n",
    "        try :\n",
    "            donnees_film[titre_html.text].append(ajout_nombre_avis_et_note(soup_film )[1])\n",
    "        except TypeError: \n",
    "            donnees_film[titre_html.text].append('vide')\n",
    "\n",
    "    return donnees_film \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut scrapping\n",
      "extracting data done\n"
     ]
    }
   ],
   "source": [
    "def extract_data() : \n",
    "    \n",
    "    \"\"\"permet de scrapper les données et écrire dans un fichier txt en format csv\"\"\"\n",
    "\n",
    "    print('debut scrapping')\n",
    "    # récupération des données\n",
    "    raw_data = get_donnees_film()\n",
    "\n",
    "    # création du dossier data s'il n'existe pas\n",
    "    if not os.path.exists(\"./data\"):\n",
    "        os.mkdir(\"./data\")\n",
    "\n",
    "    # écriture dans le fichier data_film.txt\n",
    "    with open(r'./data/data_film.txt', 'w') as f :\n",
    "        \n",
    "        for titre, info in raw_data.items() : \n",
    "\n",
    "            f.write( str(titre)+ '\\t' + str(info[0][0])+ '\\t' + str(info[0][1]) + '\\t' + str(info[0][2])\\\n",
    "            +'\\t' + str(info[1][0]) + '\\t' + str(info[1][1]) + '\\t' +str(info[2])+ '\\n' )\n",
    "    \n",
    "        f.close()\n",
    "\n",
    "    print('extracting data done')\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    extract_data()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
